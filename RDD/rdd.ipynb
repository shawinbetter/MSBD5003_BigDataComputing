{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How do I make an RDD?\n",
    "\n",
    "RDDs can be created from stable storage or by transforming other RDDs. Run the cells below to create RDDs from files on the local drive.  All data files can be downloaded from https://www.cse.ust.hk/msbd5003/data/\n",
    "For example, https://www.cse.ust.hk/msbd5003/data/fruits.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "a = sc.parallelize(range(1,100000))\n",
    "b = a.map(lambda x:math.sqrt(x))\n",
    "b.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with a: 64  lines with b:  32\n"
     ]
    }
   ],
   "source": [
    "logFile = \"../../README.md\"  # Should be some file on your system\n",
    "logData = sc.textFile(logFile)\n",
    "\n",
    "numAs = logData.filter(lambda s: 'a' in s).count()\n",
    "numBs = logData.filter(lambda s: 'b' in s).count()\n",
    "\n",
    "print(\"Lines with a:\", numAs, \" lines with b: \", numBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n",
      "['apple', 'banana', 'canary melon', 'grap', 'lemon', 'orange', 'pineapple', 'strawberry']\n",
      "['banana', 'bee', 'butter', 'canary melon', 'gold', 'lemon', 'pineapple', 'sunflower']\n"
     ]
    }
   ],
   "source": [
    "# Read data from local file system:\n",
    "print(sc.version)\n",
    "\n",
    "fruits = sc.textFile('fruits.txt')\n",
    "yellowThings = sc.textFile('yellowthings.txt')\n",
    "print(fruits.collect())\n",
    "print(yellowThings.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'banana',\n",
       " 'canary melon',\n",
       " 'grap',\n",
       " 'lemon',\n",
       " 'orange',\n",
       " 'pineapple',\n",
       " 'strawberry']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from HDFS :\n",
    "fruits = sc.textFile('fruits.txt')\n",
    "fruits.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "##  RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "fruitsReversed = fruits.map(lambda fruit: fruit[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elppa', 'ananab', 'nolem yranac', 'parg', 'nomel', 'egnaro', 'elppaenip', 'yrrebwarts']\n"
     ]
    }
   ],
   "source": [
    "# fruitsReversed = fruits.map(lambda fruit: fruit[::-1])\n",
    "fruitsReversed.persist()\n",
    "# try changing the file and re-execute with and without cache\n",
    "print(fruitsReversed.collect()) #如果persist（）被注释掉后，文件改变了，再次只运行改行代码输出的结果也会不同（因为再次执行DAG）\n",
    "# What happens when you uncomment the first line and run the whole program again with cache()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'grap', 'lemon']\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "shortFruits = fruits.filter(lambda fruit: len(fruit) <= 5)\n",
    "print(shortFruits.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'p', 'p', 'l', 'e', 'b', 'a', 'n', 'a', 'n', 'a', 'c', 'a', 'n', 'a', 'r', 'y', ' ', 'm', 'e', 'l', 'o', 'n', 'g', 'r', 'a', 'p', 'l', 'e', 'm', 'o', 'n', 'o', 'r', 'a', 'n', 'g', 'e', 'p', 'i', 'n', 'e', 'a', 'p', 'p', 'l', 'e', 's', 't', 'r', 'a', 'w', 'b', 'e', 'r', 'r', 'y']\n"
     ]
    }
   ],
   "source": [
    "# flatMap\n",
    "characters = fruits.flatMap(lambda fruit: list(fruit))#One in, any out\n",
    "print(characters.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon', 'grap', 'lemon', 'orange', 'pineapple', 'strawberry', 'banana', 'bee', 'butter', 'canary melon', 'gold', 'lemon', 'pineapple', 'sunflower']\n"
     ]
    }
   ],
   "source": [
    "# union\n",
    "fruitsAndYellowThings = fruits.union(yellowThings) #这个只是单纯并集，允许有重复元素出现 #concatnation\n",
    "print(fruitsAndYellowThings.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pineapple', 'canary melon', 'lemon', 'banana']\n"
     ]
    }
   ],
   "source": [
    "# intersection\n",
    "yellowFruits = fruits.intersection(yellowThings)\n",
    "print(yellowFruits.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orange', 'pineapple', 'canary melon', 'lemon', 'bee', 'banana', 'butter', 'gold', 'sunflower', 'apple', 'grap', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "# distinct\n",
    "distinctFruitsAndYellowThings = fruitsAndYellowThings.distinct()\n",
    "print(distinctFruitsAndYellowThings.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD actions\n",
    "Following are examples of some of the common actions available. For a detailed list, see [RDD Actions](https://spark.apache.org/docs/2.0.0/programming-guide.html#actions).\n",
    "\n",
    "Run some transformations below to understand this better. Place the cursor in the cell and press **SHIFT + ENTER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon', 'grap', 'lemon', 'orange', 'pineapple', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "# collect\n",
    "fruitsArray = fruits.collect()\n",
    "yellowThingsArray = yellowThings.collect()\n",
    "print(fruitsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# count\n",
    "numFruits = fruits.count()\n",
    "print(numFruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon']\n"
     ]
    }
   ],
   "source": [
    "# take\n",
    "first3Fruits = fruits.take(3)\n",
    "print(first3Fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(fruits.map(lambda fruit: len(fruit)).sum())\n",
    "#Must be Associative Operator (Dont care about the position)\n",
    "print(fruits.map(lambda fruit: len(fruit)).reduce(lambda x,y : x+y)) #两两操作后结果和另外item操作 #和mapreduce不同，那个是reduct by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# reduce\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).reduce(lambda x, y: x.union(y)) #union is python union (distinct)\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'l', 'b', 'c', 'r', 'y', 'g', 'i', 's', 'a', 'e', 'n', ' ', 'm', 'o', 't', 'w']\n"
     ]
    }
   ],
   "source": [
    "letterSet = fruits.flatMap(lambda fruit: list(fruit)).distinct().collect()\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "0\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "rdd = sc.parallelize(range(10))\n",
    "\n",
    "# Wrong: Don't do this!!\n",
    "def increment_counter(x):\n",
    "    global counter\n",
    "    counter += x\n",
    "\n",
    "print(rdd.collect())\n",
    "rdd.foreach(increment_counter) #another action\n",
    "\n",
    "print(counter)\n",
    "print(rdd.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "\n",
    "a = rdd.foreach(g)\n",
    "\n",
    "print(accum.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45\n",
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(0) #avoid\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "    return x * x\n",
    "\n",
    "a = rdd.map(g) # = foreach\n",
    "print(accum.value)\n",
    "\n",
    "a.reduce(lambda x, y: x+y) #action make accum+\n",
    "print(accum.value)\n",
    "\n",
    "a.cache()\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "\n",
    "rdd.reduce(lambda x, y: x+y)\n",
    "\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "# print(rdd.reduce(lambda x, y: x+y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Pi using Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.141436\n"
     ]
    }
   ],
   "source": [
    "# From the official spark examples.\n",
    "import random\n",
    "import time\n",
    "\n",
    "partitions = 100\n",
    "n = 10000 * partitions\n",
    "\n",
    "def f(_):\n",
    "    x = random.random()\n",
    "    y = random.random()\n",
    "    return 1 if x ** 2 + y ** 2 <= 1 else 0\n",
    "\n",
    "count = sc.parallelize(range(1, n + 1), partitions).map(f).sum()\n",
    "\n",
    "print(\"Pi is roughly\", 4.0 * count / n) #求正方形中落入圆中点的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]\n",
      "[[0.6701936982081924], [0.09669661577798527], [0.6014414561231274], [0.332997328120584], [0.22897696253426958], [0.46577948640799915], [0.8467279083466749], [0.8181700240513209], [0.46102514877904677], [0.26939396481088207]]\n"
     ]
    }
   ],
   "source": [
    "# Example: glom\n",
    "import sys\n",
    "import random\n",
    "\n",
    "def f(_):\n",
    "    return random.random()\n",
    "\n",
    "a = sc.parallelize(range(0,10),10)\n",
    "print(a.collect())\n",
    "print(a.glom().collect()) #glom() convert RDD to list of lists\n",
    "print(a.map(f).glom().collect())\n",
    "\n",
    "# Weird behavior: Initially, random numbers are synched across all workers, but will get \n",
    "# out-of-sync after a large (e.g, 1000000) number of random numbers have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]\n",
      "[0, 1, 3, 6, 10, 5, 11, 18, 26, 35, 10, 21, 33, 46, 60, 15, 31, 48, 66, 85]\n",
      "[0, 1, 3, 6, 10, 6, 12, 19, 27, 36, 12, 23, 35, 48, 62, 18, 34, 51, 69, 88]\n"
     ]
    }
   ],
   "source": [
    "# Example: mapPartition and mapPartitionWithIndex\n",
    "a = sc.parallelize(range(0,20),4)\n",
    "print(a.glom().collect())\n",
    "\n",
    "def f(it):\n",
    "    s = 0\n",
    "    for i in it: #this for loop will only trigger when an action call it.\n",
    "        s += i\n",
    "        yield s #without construct list explicitly. Everything yielded will be append into a list\n",
    "\n",
    "print(a.mapPartitions(f).collect()) #map based on each partition\n",
    "\n",
    "def f(index, it): #index retrieves the number of partition (starts with 0)\n",
    "    s = index\n",
    "    for i in it:\n",
    "        s += i\n",
    "        yield s\n",
    "\n",
    "print(a.mapPartitionsWithIndex(f).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.144788\n"
     ]
    }
   ],
   "source": [
    "# Correct version\n",
    "import random\n",
    "import time\n",
    "\n",
    "partitions = 100\n",
    "n = 10000 * partitions\n",
    "\n",
    "seed = time.time()\n",
    "\n",
    "def f(index, it):\n",
    "    random.seed(index + seed) #ensure every work use different seed\n",
    "    for i in it:\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        yield 1 if x ** 2 + y ** 2 < 1 else 0\n",
    "\n",
    "count = sc.parallelize(range(1, n + 1), partitions) \\\n",
    "          .mapPartitionsWithIndex(f).sum() #different seeds fro diffrent partition\n",
    "\n",
    "print(\"Pi is roughly\", 4.0 * count / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closure and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD variables are references\n",
    "A = sc.parallelize(range(10)) #2*x + 1\n",
    "B = A.map(lambda x: x*2)\n",
    "A = B.map(lambda x: x+1)\n",
    "A.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# Linear-time selection\n",
    "\n",
    "data = [34, 67, 21, 56, 47, 89, 12, 44, 74, 43, 26]\n",
    "A = sc.parallelize(data,8)\n",
    "k = 4\n",
    "\n",
    "while True:\n",
    "    x = A.first()\n",
    "    A1 = A.filter(lambda z: z < x)\n",
    "    A2 = A.filter(lambda z: z > x)\n",
    "    # print('X:',x)\n",
    "#     print('K:',k)\n",
    "#     print('A:',A.collect())\n",
    "#     print('A1:',A1.collect())\n",
    "    # print('A2:',A2.collect())\n",
    "#     print('----------')\n",
    "    mid = A1.count() \n",
    "    if mid == k:\n",
    "        print(x)\n",
    "        break\n",
    "    if k < mid:\n",
    "        A = A1\n",
    "    else:\n",
    "        A = A2\n",
    "        k = k - mid - 1\n",
    "    A.cache() #Actually it caches the A2 part, while the A1 part is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 21, 26, 34, 43, 44, 47, 56, 67, 74, 89]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(range(10))\n",
    "\n",
    "x = 5\n",
    "B = A.filter(lambda z: z < x)\n",
    "B.cache() #if comment it, the B will re-compute \n",
    "print(B.count())\n",
    "x = 3\n",
    "print(B.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(range(10))\n",
    "\n",
    "x = 5\n",
    "B = A.filter(lambda z: z < x)\n",
    "# B.cache()\n",
    "B.unpersist()\n",
    "# print(B.take(10))\n",
    "print(B.collect())\n",
    "\n",
    "x = 3\n",
    "#print(B.take(10))\n",
    "print(B.collect())\n",
    "# collect() doesn't always re-collect data - bad design!\n",
    "# Always use take() instead of collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key-Value Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2), (12, 1), (4, 1), (10, 1), (5, 2), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "# reduceByKey\n",
    "numFruitsByLength = fruits.map(lambda fruit: (len(fruit), 1)).reduceByKey(lambda x, y: x + y) #相同的key的value相加，相当于word count\n",
    "print(numFruitsByLength.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Big', 1), ('Course', 2), ('Description', 1), ('Information', 1), ('Lecture', 1), ('This', 1), ('across', 1), ('amount', 1), ('and', 3), ('as', 1), ('both', 1), ('centers.', 1), ('cloud', 1), ('commodity', 1), ('computing', 1), ('course', 1), ('data', 4), ('emerge', 1), ('enabling', 1), ('even', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Word Count\n",
    "from operator import add\n",
    "\n",
    "lines = sc.textFile('course.txt')\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "# counts.collect()\n",
    "print(counts.sortByKey().take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 4), ('of', 3), ('and', 3), ('Course', 2), ('in', 2), ('the', 2), ('Information', 1), ('systems,', 1), ('cloud', 1), ('parallel', 1), ('as', 1), ('mining', 1), ('massive', 1), ('amount', 1), ('even', 1), ('servers', 1), ('centers.', 1), ('both', 1), ('hands-on', 1), ('this', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(counts.sortBy(lambda x: x[1], False).take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ('Apple', (134, 'OK'))), (1, ('Apple', (135, 'OK'))), (1, ('Apple', (45, 'OK'))), (2, ('Orange', (53, 'OK'))), (3, ('TV', (34, 'OK'))), (5, ('Computer', (162, 'Error')))]\n"
     ]
    }
   ],
   "source": [
    "# Join simple example\n",
    "\n",
    "products = sc.parallelize([(1, \"Apple\"), (2, \"Orange\"), (3, \"TV\"), (5, \"Computer\")])\n",
    "#trans = sc.parallelize([(1, 134, \"OK\"), (3, 34, \"OK\"), (5, 162, \"Error\"), (1, 135, \"OK\"), (2, 53, \"OK\"), (1, 45, \"OK\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "print(products.join(trans).take(20)) #for key = 1,product three matchings in the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final centers:  [array([0.1       , 0.33333333, 0.23333333]), array([9.05, 3.05, 4.65]), array([9.2, 2.2, 9.2])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parseVector(line):\n",
    "    return np.array([float(x) for x in line.split()])\n",
    "\n",
    "def closestPoint(p, centers):\n",
    "    bestIndex = 0\n",
    "    closest = float(\"+inf\")\n",
    "    for i in range(len(centers)):\n",
    "        tempDist = np.sum((p - centers[i]) ** 2)\n",
    "        if tempDist < closest:\n",
    "            closest = tempDist\n",
    "            bestIndex = i\n",
    "    return bestIndex\n",
    "\n",
    "# The data file can be downloaded at http://www.cse.ust.hk/msbd5003/data/kmeans_data.txt\n",
    "lines = sc.textFile('kmeans_data.txt', 5)  \n",
    "\n",
    "# The data file can be downloaded at http://www.cse.ust.hk/msbd5003/data/kmeans_bigdata.txt\n",
    "# lines = sc.textFile('../data/kmeans_bigdata.txt', 5)  \n",
    "# lines is an RDD of strings\n",
    "K = 3\n",
    "convergeDist = 0.01  \n",
    "# terminate algorithm when the total distance from old center to new centers is less than this value\n",
    "\n",
    "data = lines.map(parseVector).cache() # data is an RDD of arrays\n",
    "\n",
    "kCenters = data.takeSample(False, K, 1)  # intial centers as a list of arrays\n",
    "tempDist = 1.0  # total distance from old centers to new centers\n",
    "\n",
    "while tempDist > convergeDist:\n",
    "    closest = data.map(lambda p: (closestPoint(p, kCenters), (p, 1)))\n",
    "    # for each point in data, find its closest center\n",
    "    # closest is an RDD of tuples (index of closest center, (point, 1))\n",
    "        \n",
    "    pointStats = closest.reduceByKey(lambda p1, p2: (p1[0] + p2[0], p1[1] + p2[1]))\n",
    "    # pointStats is an RDD of tuples (index of center,\n",
    "    # (array of sums of coordinates, total number of points assigned))\n",
    "    \n",
    "    newCenters = pointStats.map(lambda st: (st[0], st[1][0] / st[1][1])).collect()\n",
    "    # compute the new centers\n",
    "    \n",
    "    tempDist = sum(np.sum((kCenters[i] - p) ** 2) for (i, p) in newCenters)\n",
    "    # compute the total disctance from old centers to new centers\n",
    "    \n",
    "    for (i, p) in newCenters:\n",
    "\n",
    "        kCenters[i] = p\n",
    "        \n",
    "print(\"Final centers: \", kCenters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:>                                                        (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 16775.735268839184), ('2', 15259.179382798724), ('1', 10159.700782343547), ('4', 8992.664552292099), ('5', 7293.343859690148)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from operator import add\n",
    "\n",
    "def computeContribs(urls, rank):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    #urls is a list of neighbour node\n",
    "    #rank is the current weight of the current node\n",
    "    num_urls = len(urls)\n",
    "    for url in urls:\n",
    "        yield (url, rank / num_urls)  #return a list of contribution\n",
    "\n",
    "def parseNeighbors(urls):\n",
    "    # Parses a urls pair string into urls pair.\"\"\"\n",
    "    parts = urls.split(' ')\n",
    "    return parts[0], parts[1]\n",
    "\n",
    "# Loads in input file. It should be in format of:\n",
    "#     URL         neighbor URL\n",
    "#     URL         neighbor URL\n",
    "#     URL         neighbor URL\n",
    "#     ...\n",
    "\n",
    "# The data file can be downloaded at http://www.cse.ust.hk/msbd5003/data/*\n",
    "# lines = sc.textFile(\"pagerank_data.txt\", 2)\n",
    "lines = sc.textFile(\"dblp.in.txt\", 5)\n",
    "\n",
    "numOfIterations = 10\n",
    "\n",
    "# Loads all URLs from input file and initialize their neighbors. \n",
    "links = lines.map(lambda urls: parseNeighbors(urls)) \\\n",
    "             .groupByKey() #ajacent list of the total graph\n",
    "\n",
    "# Loads all URLs with other URL(s) link to from input file \n",
    "# and initialize ranks of them to one.\n",
    "ranks = links.mapValues(lambda neighbors: 1.0) #not change the key, the change the value part of the links\n",
    "#(node,1.0)\n",
    "\n",
    "# Calculates and updates URL ranks continuously using PageRank algorithm.\n",
    "for iteration in range(numOfIterations):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    contribs = links.join(ranks) \\\n",
    "                    .flatMap(lambda url_urls_rank:\n",
    "                             computeContribs(url_urls_rank[1][0],\n",
    "                                             url_urls_rank[1][1]))\n",
    "    # After the join, each element in the RDD is of the form\n",
    "    # (url, (list of neighbor urls, rank))\n",
    "    \n",
    "    # Re-calculates URL ranks based on neighbor contributions.\n",
    "    ranks = contribs.reduceByKey(add).mapValues(lambda rank: rank * 0.85 + 0.15)\n",
    "    # ranks = contribs.reduceByKey(add).map(lambda t: (t[0], t[1] * 0.85 + 0.15))\n",
    "\n",
    "print(ranks.top(5, lambda x: x[1])) #the only action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join vs. Broadcast Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ((134, 'OK'), 'Apple')), (1, ((135, 'OK'), 'Apple')), (1, ((45, 'OK'), 'Apple')), (2, ((53, 'OK'), 'Orange')), (3, ((34, 'OK'), 'TV')), (5, ((162, 'Error'), 'Computer'))]\n"
     ]
    }
   ],
   "source": [
    "products = sc.parallelize([(1, \"Apple\"), (2, \"Orange\"), (3, \"TV\"), (5, \"Computer\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "print(trans.join(products).take(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Apple', (134, 'OK')), (3, 'TV', (34, 'OK')), (5, 'Computer', (162, 'Error')), (1, 'Apple', (135, 'OK')), (2, 'Orange', (53, 'OK')), (1, 'Apple', (45, 'OK'))]\n"
     ]
    }
   ],
   "source": [
    "products = {1: \"Apple\", 2: \"Orange\", 3: \"TV\", 5: \"Computer\"}\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "broadcasted_products = sc.broadcast(products) #better\n",
    "\n",
    "results = trans.map(lambda x: (x[0], broadcasted_products.value[x[0]], x[1]))\n",
    "#  results = trans.map(lambda x: (x[0], products[x[0]], x[1]))\n",
    "print(results.take(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "v = spark.createDataFrame([\n",
    " (\"a\", \"Alice\", 34),\n",
    " (\"b\", \"Bob\", 36),\n",
    " (\"c\", \"Charlie\", 37),\n",
    " (\"d\", \"David\", 29),\n",
    " (\"e\", \"Esther\", 32),\n",
    " (\"f\", \"Fanny\", 38),\n",
    " (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame\n",
    "e = spark.createDataFrame([\n",
    " (\"a\", \"b\", \"follow\"),\n",
    " (\"a\", \"c\", \"friend\"),\n",
    " (\"a\", \"g\", \"friend\"),\n",
    " (\"b\", \"c\", \"friend\"),\n",
    " (\"c\", \"a\", \"friend\"),\n",
    " (\"c\", \"b\", \"friend\"),\n",
    " (\"c\", \"d\", \"follow\"),\n",
    " (\"c\", \"g\", \"friend\"),\n",
    " (\"d\", \"a\", \"follow\"),\n",
    " (\"d\", \"g\", \"friend\"),\n",
    " (\"e\", \"a\", \"follow\"),\n",
    " (\"e\", \"d\", \"follow\"),\n",
    " (\"f\", \"b\", \"follow\"),\n",
    " (\"f\", \"c\", \"follow\"),\n",
    " (\"f\", \"d\", \"follow\"),\n",
    " (\"g\", \"a\", \"friend\"),\n",
    " (\"g\", \"c\", \"friend\"),\n",
    " (\"g\", \"d\", \"friend\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "# FILL IN YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 4\n",
    "rdd = sc.parallelize([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0], p)\n",
    "                     \n",
    "def find_longest_one(Index,it):\n",
    "    \n",
    "    start,index = 0,-1\n",
    "    record_start,record_end,max_len = 0,0,0\n",
    "    \n",
    "    indicator = True #indicate previous element is 1 or not,default to 1\n",
    "    \n",
    "    current_len = 0 #length of consective 1s\n",
    "    for i in it:\n",
    "        index +=1 #record current index\n",
    "        \n",
    "        if i == 1:\n",
    "            if indicator == True: #previous is 1\n",
    "                current_len = index - start + 1\n",
    "                \n",
    "                if current_len > max_len:\n",
    "                    record_start = start\n",
    "                    record_end = index\n",
    "                    max_len = current_len\n",
    "                    \n",
    "            else: #previous is not 1\n",
    "                start = index\n",
    "                indicator = True\n",
    "                current_len = 0\n",
    "            \n",
    "        else:\n",
    "            if indicator == True: #previous is 1\n",
    "                indicator = False\n",
    "                \n",
    "            else: #previous is not 1\n",
    "                current_len = 0\n",
    "                \n",
    "    # (Partition Index, nums of element, record start,record end, max len)     \n",
    "    yield [Index,index+1,record_start,record_end,max_len] #\n",
    "\n",
    "ans = rdd.mapPartitionsWithIndex(find_longest_one).collect()\n",
    "\n",
    "previous_count = []\n",
    "for i in ans:\n",
    "    i[2] += sum(previous_count)\n",
    "    i[3] += sum(previous_count)\n",
    "    previous_count.append(i[1])\n",
    "\n",
    "longest = 0\n",
    "for i in range(1,len(ans)):\n",
    "    tmp = ans[i][4]\n",
    "    if ans[i-1][3] + 1 == ans[i][2]:\n",
    "        tmp += ans[i-1][4]\n",
    "        longest = max(longest,tmp)\n",
    "    else:\n",
    "        longest = max(longest,tmp)\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = sc.parallelize([1,2,3,4])\n",
    "RDD2 = sc.parallelize([1,2,3,4])\n",
    "\n",
    "r1 = RDD1.zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "r2 = RDD2.zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "RDD3 = r1.union(r2).reduceByKey(lambda x,y: x*y).map(lambda x: x[1])\n",
    "dot_product = RDD3.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (2, 3), (3, 4)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 2), (4, 3)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1.zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 2), (4, 3)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD2.zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 4), (2, 9), (3, 16)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.union(r2).reduceByKey(lambda x,y: x*y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
